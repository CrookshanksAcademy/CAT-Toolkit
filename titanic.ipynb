# Introduction

This is a complete, end-to-end exploration of the **Titanic** dataset. It includes:

- Feature engineering  
- Missing value imputation (using `mice`)  
- A `randomForest` model for survival  
- **New**: A compact but rigorous **statistical inference pass** (t-tests, F-tests, ANOVAs, correlations, simple regression) with interpretations and effect sizes.

## Reproducibility & Packages

```{r, message=FALSE, warning=FALSE}
# Core visualization and data manipulation
library(ggplot2)
library(ggthemes)
library(scales)
library(dplyr)

# Imputation and modeling
library(mice)
library(randomForest)

# For ranking in variable-importance section
library(tidyr)
library(stringr)
library(stats)

# Set a global seed for reproducibility where relevant
set.seed(42)
````

# Load & Inspect Data

```{r, message=FALSE, warning=FALSE}
# Kaggle Titanic paths
train <- read.csv('../input/train.csv', stringsAsFactors = FALSE)
test  <- read.csv('../input/test.csv',  stringsAsFactors = FALSE)

# Combine for joint feature engineering, then split back later
full  <- bind_rows(train, test)

# Quick structural check
str(full)
```

We have **1,309** rows and **12** variables (train: 891 with `Survived`, test: 418 without). The columns are:

| Variable    | Description               |
| ----------- | ------------------------- |
| Survived    | Survived (1) or died (0)  |
| Pclass      | Passenger's class (1–3)   |
| Name        | Passenger's name          |
| Sex         | Passenger's sex           |
| Age         | Passenger's age           |
| SibSp       | # siblings/spouses aboard |
| Parch       | # parents/children aboard |
| Ticket      | Ticket number             |
| Fare        | Fare                      |
| Cabin       | Cabin                     |
| Embarked    | Port of embarkation       |
| PassengerId | Row identifier            |

# Feature Engineering

## What's in a name?

We extract **Title** from `Name` and **Surname** for family grouping.

```{r, message=FALSE, warning=FALSE}
# Title from Name (substring before '.' after a comma)
full$Title <- gsub('(.*, )|(\\..*)', '', full$Name)

# Look at titles by sex
table(full$Sex, full$Title)

# Consolidate rare titles and harmonize variants
rare_title <- c('Dona','Lady','the Countess','Capt','Col','Don',
                'Dr','Major','Rev','Sir','Jonkheer')

full$Title[full$Title == 'Mlle'] <- 'Miss'
full$Title[full$Title == 'Ms']   <- 'Miss'
full$Title[full$Title == 'Mme']  <- 'Mrs'
full$Title[full$Title %in% rare_title] <- 'Rare Title'

# Re-check
table(full$Sex, full$Title)

# Surname
full$Surname <- sapply(full$Name, function(x) strsplit(x, split='[,.]')[[1]][1])

# Report unique surnames
cat(sprintf("We have %d unique surnames.\n", nlevels(factor(full$Surname))))
```

## Families: do they sink or swim together?

Create **Family Size** and a helper family label.

```{r}
# Family Size (include self)
full$Fsize <- full$SibSp + full$Parch + 1

# Family label "Surname_Size"
full$Family <- paste(full$Surname, full$Fsize, sep='_')

# Visualize Fsize vs survival (training rows only)
ggplot(full[1:891,], aes(x = Fsize, fill = factor(Survived))) +
  geom_bar(stat='count', position='dodge') +
  scale_x_continuous(breaks = 1:11) +
  labs(x = 'Family Size', fill = 'Survived') +
  theme_few()
```

Discretize **Fsize** into `singleton`, `small`, `large`.

```{r}
full$FsizeD <- NA_character_
full$FsizeD[full$Fsize == 1] <- 'singleton'
full$FsizeD[full$Fsize > 1 & full$Fsize < 5] <- 'small'
full$FsizeD[full$Fsize >= 5] <- 'large'
full$FsizeD <- factor(full$FsizeD, levels = c('singleton','small','large'))

# Mosaic of FsizeD vs survival (train only)
mosaicplot(table(full$FsizeD[1:891], full$Survived[1:891]),
           main='Family Size by Survival', shade=TRUE)
```

## Deck from Cabin (sparse but sometimes useful)

```{r}
# First character of Cabin is deck letter; many NAs
full$Deck <- factor(sapply(full$Cabin, function(x) strsplit(x, NULL)[[1]][1]))
```

# Missingness & Imputation

We will **impute `Embarked`, `Fare`, and `Age`** where missing.

## Sensible value imputation (Embarked, Fare)

Two training passengers (IDs 62, 830) have missing `Embarked`.

```{r}
# Show their current rows
full[c(62, 830), c('PassengerId','Pclass','Fare','Embarked')]
```

Use fare/class distribution to infer likely port:

```{r, message=FALSE, warning=FALSE}
embark_fare <- full %>% filter(PassengerId != 62 & PassengerId != 830)

ggplot(embark_fare, aes(x = Embarked, y = Fare, fill = factor(Pclass))) +
  geom_boxplot() +
  geom_hline(aes(yintercept = 80), linetype='dashed', size=1) +
  scale_y_continuous(labels = dollar_format()) +
  labs(title = 'Fare by Embarked and Pclass', fill = 'Pclass') +
  theme_few()

# Assign 'C' (Cherbourg) for those two based on distribution
full$Embarked[c(62, 830)] <- 'C'
```

One passenger (row 1044) has missing `Fare`. Impute by median of same `Pclass` & `Embarked`.

```{r, message=FALSE, warning=FALSE}
full[1044, c('PassengerId','Pclass','Embarked','Fare')]

median_fare <- median(full$Fare[full$Pclass == '3' & full$Embarked == 'S'], na.rm = TRUE)
ggplot(full[full$Pclass=='3' & full$Embarked=='S', ], aes(x = Fare)) +
  geom_density(alpha = 0.4) +
  geom_vline(xintercept = median_fare, linetype='dashed') +
  scale_x_continuous(labels = dollar_format()) +
  labs(title = 'Fare distribution: Pclass 3, Embarked S')

# Impute
full$Fare[1044] <- median_fare
```

## Predictive imputation (Age via MICE)

We use `mice` (random forest method) to impute `Age`.

```{r, message=FALSE, warning=FALSE}
# Factorize categorical variables for mice
factor_vars <- c('PassengerId','Pclass','Sex','Embarked',
                 'Title','Surname','Family','FsizeD')

full[factor_vars] <- lapply(full[factor_vars], factor)

# Set a seed for mice reproducibility
set.seed(129)

# Exclude unhelpful or leakage-prone variables from imputation matrix
mice_vars <- !names(full) %in% c('PassengerId','Name','Ticket','Cabin','Family','Surname','Survived')

mice_mod <- mice(full[, mice_vars], method='rf', printFlag = FALSE)
mice_output <- complete(mice_mod)

# Compare distributions
par(mfrow=c(1,2))
hist(full$Age,        freq=FALSE, main='Age: Original', col='#4daf4a', ylim=c(0,0.04))
hist(mice_output$Age, freq=FALSE, main='Age: MICE Imputed', col='#9ae79a', ylim=c(0,0.04))
par(mfrow=c(1,1))

# Replace Age in full with imputed Age
full$Age <- mice_output$Age

# Sanity check: any missing Age?
sum(is.na(full$Age))
```

## Age-derived features (Child, Mother)

```{r, message=FALSE, warning=FALSE}
# Relationship between Age & Survived (train only)
ggplot(full[1:891,], aes(Age, fill = factor(Survived))) +
  geom_histogram() +
  facet_grid(.~Sex) +
  labs(fill='Survived') +
  theme_few()

# Child (under 18) vs Adult
full$Child <- ifelse(full$Age < 18, 'Child', 'Adult')
full$Child <- factor(full$Child)

# Mother: female, >18, Parch>0, Title != 'Miss'
full$Mother <- 'Not Mother'
full$Mother[full$Sex == 'female' & full$Age > 18 & full$Parch > 0 & full$Title != 'Miss'] <- 'Mother'
full$Mother <- factor(full$Mother)

# Missingness pattern check (informative, not required to run every time)
md.pattern(full)
```

# Statistical Tests & Inference

We now add a **stats pass** to uncover structure in the data.
**Why skip some tests?**

* **One-sample z-test**: requires *known* population SD; we don’t have it → use t-test instead.
* **Paired t-test**: needs paired (before/after) measures on the **same** individuals → not present here.
* **Chi-square variance test**: compares a sample variance to a *specified* population variance; no meaningful σ² to test against.

We **include**: one-sample t-test, two-sample (pooled) t-test, **Welch’s t-test**, **F-test for variances**, **one-way ANOVA**, **Welch’s ANOVA**, **two-way ANOVA**, **correlations**, and a **simple linear regression**.

```{r, message=FALSE, warning=FALSE}
# Work on train set where Survived is available
train <- full[1:891, ]

# Useful log scale for heavy-tailed Fare (keeps zeros safe)
train$logFare <- log1p(train$Fare)
full$logFare  <- log1p(full$Fare)

# ---------------------------
# Helper functions for effect sizes and pretty printing
# ---------------------------
cohen_d <- function(x, y) {
  x <- x[is.finite(x)]; y <- y[is.finite(y)]
  n1 <- length(x); n2 <- length(y)
  s1 <- var(x); s2 <- var(y)
  sp <- sqrt(((n1-1)*s1 + (n2-1)*s2)/(n1+n2-2))
  (mean(x) - mean(y)) / sp
}

eta_sq_oneway <- function(aov_obj) {
  at <- anova(aov_obj)
  at[1, "Sum Sq"] / sum(at[, "Sum Sq"])
}

eta_sq_partial_two_way <- function(aov_obj) {
  at <- anova(aov_obj)
  ss_error <- at["Residuals","Sum Sq"]
  effects <- rownames(at)[rownames(at)!="Residuals"]
  out <- sapply(effects, function(eff) at[eff,"Sum Sq"]/(at[eff,"Sum Sq"] + ss_error))
  out
}

pretty_p <- function(p) ifelse(p < .001, "< 0.001", sprintf("= %.3f", p))
```

## 1) One-sample t-test: mean Age vs 30

```{r}
one_sample_t <- t.test(train$Age, mu = 30)
one_sample_t

cat(sprintf("\nInference: Mean Age = %.2f (SD = %.2f). p %s → the mean age is %s 30.\n",
            mean(train$Age), sd(train$Age), pretty_p(one_sample_t$p.value),
            ifelse(one_sample_t$p.value < .05, "statistically different from", "not statistically different from")))
```

**Meaning:** Typical passenger age hovers around \~30; any difference is small in practical terms.

## 2) Variances & Means by Sex: F-test, pooled t, and Welch t (Age \~ Sex)

```{r}
# Variance equality (F-test)
f_var_age_sex <- var.test(Age ~ Sex, data = train)
f_var_age_sex

# Pooled two-sample t-test (assumes equal variances)
t_equal_age_sex <- t.test(Age ~ Sex, data = train, var.equal = TRUE)
t_equal_age_sex

# Welch's t-test (robust to unequal variances)
t_welch_age_sex <- t.test(Age ~ Sex, data = train, var.equal = FALSE)
t_welch_age_sex

# Effect size (female - male)
d_age_sex <- with(train, cohen_d(Age[Sex=="female"], Age[Sex=="male"]))

cat(sprintf("\nInference: Age ~ Sex → pooled t p %s; Welch p %s. Cohen's d = %.2f (0.2 small, 0.5 medium, 0.8 large).\n",
            pretty_p(t_equal_age_sex$p.value),
            pretty_p(t_welch_age_sex$p.value),
            d_age_sex))
```

**Meaning:** Women are slightly younger on average; the effect is typically small to modest.

## 3) Welch’s t-test: Age by Survival (Age \~ Survived)

```{r}
t_welch_age_surv <- t.test(Age ~ Survived, data = train, var.equal = FALSE)
t_welch_age_surv

d_age_surv <- with(train, cohen_d(Age[Survived==1], Age[Survived==0]))

cat(sprintf("\nInference: Survivors vs Non-survivors differ in Age (Welch p %s). Cohen's d = %.2f.\n",
            pretty_p(t_welch_age_surv$p.value), d_age_surv))
```

**Meaning:** Survivors tend to be younger by a few years (small-to-moderate effect).

## 4) One-way ANOVA: log Fare by Pclass

```{r}
aov_pclass <- aov(logFare ~ Pclass, data = train)
summary(aov_pclass)

eta2_pclass <- eta_sq_oneway(aov_pclass)
cat(sprintf("\nEffect size: eta^2(Pclass) = %.2f (≈0.01 small, 0.06 medium, 0.14 large).\n", eta2_pclass))
```

**Meaning:** Very strong class effect—1st class paid far more than 2nd/3rd (large eta²).

## 5) Welch’s ANOVA: log Fare by Embarked (heteroskedastic)

```{r}
welch_embarked <- oneway.test(logFare ~ Embarked, data = train) # Welch version
welch_embarked

cat(sprintf("\nInference: Fares differ across ports (Welch ANOVA p %s). Cherbourg (C) often shows higher fares.\n",
            pretty_p(welch_embarked$p.value)))
```

**Meaning:** Port of embarkation is associated with fare (C > S, Q, typically due to many 1st-class passengers at C).

## 6) Two-way ANOVA: log Fare \~ Sex \* Pclass

```{r}
aov_two_way <- aov(logFare ~ Sex * Pclass, data = train)
summary(aov_two_way)

etas <- eta_sq_partial_two_way(aov_two_way)
etas

cat(sprintf("\nPartial eta^2 — Sex: %.2f, Pclass: %.2f, Sex×Pclass: %.2f.\n",
            etas["Sex"], etas["Pclass"], ifelse("Sex:Pclass" %in% names(etas), etas["Sex:Pclass"], NA)))
```

**Meaning:** `Pclass` dominates variance in fare; `Sex` is minor; the interaction is typically small.

## 7) Correlations

* **Spearman** (monotonic): Pclass (ordinal) vs Fare
* **Pearson** (linear): Age vs Fare

```{r}
cor_pclass_fare <- cor.test(train$Pclass, train$Fare, method = "spearman")
cor_age_fare    <- cor.test(train$Age,     train$Fare, method = "pearson")

cor_pclass_fare
cor_age_fare

cat(sprintf("\nInference: Pclass vs Fare (Spearman rho) p %s; Age vs Fare (Pearson r) p %s.\n",
            pretty_p(cor_pclass_fare$p.value), pretty_p(cor_age_fare$p.value)))
```

**Meaning:** Strong negative association between class number and fare; Age–Fare correlation is weak.

## 8) Simple Linear Regression: log Fare \~ Pclass

```{r}
lm_simple <- lm(logFare ~ Pclass, data = train)
summary(lm_simple)

cat(sprintf("\nInference: Pclass substantially predicts log Fare (R^2 = %.2f).\n",
            summary(lm_simple)$r.squared))
```

**Meaning:** Each step down in class reduces expected fare multiplicatively (because of log link).

## Summary Tables (sanity checks)

```{r}
train %>%
  group_by(Sex) %>%
  summarise(n = n(), mean_age = mean(Age), sd_age = sd(Age)) %>% print()

train %>%
  group_by(Survived) %>%
  summarise(n = n(), mean_age = mean(Age), sd_age = sd(Age)) %>% print()

train %>%
  group_by(Pclass) %>%
  summarise(n = n(),
            mean_fare = mean(Fare),
            median_fare = median(Fare),
            mean_logFare = mean(logFare)) %>% print()

train %>%
  group_by(Embarked) %>%
  summarise(n = n(),
            mean_fare = mean(Fare),
            median_fare = median(Fare)) %>% print()
```

# Prediction (Random Forest)

We now return to modeling survival using `randomForest` with the engineered features.

## Split back to train/test

```{r}
# Split the data back into a train and a test set
train <- full[1:891,]
test  <- full[892:1309,]
```

## Build the model

```{r}
set.seed(754)

rf_model <- randomForest(
  factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + 
                     Fare + Embarked + Title + 
                     FsizeD + Child + Mother,
  data = train
)

# Error plot
plot(rf_model, ylim = c(0, 0.36))
legend('topright', colnames(rf_model$err.rate), col = 1:3, fill = 1:3)
```

The black line is overall error (< \~20%); red/green are class-wise errors (often easier to predict non-survival than survival).

## Variable importance

```{r, message=FALSE, warning=FALSE}
imp <- importance(rf_model)
varImportance <- data.frame(
  Variables = row.names(imp),
  Importance = round(imp[ ,'MeanDecreaseGini'], 2),
  row.names = NULL
)

rankImportance <- varImportance %>%
  arrange(desc(Importance)) %>%
  mutate(Rank = paste0('#', dense_rank(desc(Importance))))

ggplot(rankImportance, aes(x = reorder(Variables, Importance), y = Importance, fill = Importance)) +
  geom_bar(stat='identity') +
  geom_text(aes(y = 0.5, label = Rank), hjust = 0, vjust = 0.55, size = 4, colour = 'red') +
  labs(x = 'Variables', title = 'Random Forest — Mean Decrease Gini') +
  coord_flip() +
  theme_few()
```

**Interpretation:** Social/structural variables tied to cabin class/wealth and demographics (e.g., **Title**, **Pclass**, **Sex**, **Fare**, **Age**) rank high—consistent with the inferential results.

## Predict & Save submission

```{r}
prediction <- predict(rf_model, test)

# Kaggle expects "PassengerId" not "PassengerID"
solution <- data.frame(PassengerId = test$PassengerId, Survived = prediction)

write.csv(solution, file = 'rf_mod_Solution.csv', row.names = FALSE)

# Preview
head(solution)
```

# Conclusion

